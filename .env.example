# Database Configuration
MONGO_URI=mongodb://localhost:27017
MONGO_DB_NAME=litellm_gateway

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Cache Configuration
CACHE_TTL=3600

# LLM Provider API Keys
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
COHERE_API_KEY=your_cohere_key_here
GOOGLE_API_KEY=your_google_key_here
AZURE_API_KEY=your_azure_key_here

# LLM Provider Custom API Base URLs (optional)
# Use these to override default provider endpoints
OPENAI_API_BASE=https://api.openai.com/v1
ANTHROPIC_API_BASE=https://api.anthropic.com
COHERE_API_BASE=https://api.cohere.ai
GOOGLE_API_BASE=your_vertex_ai_project_id
AZURE_API_BASE=https://your-resource.openai.azure.com

# Custom Provider Support (for private/self-hosted models)
CUSTOM_LLM_PROVIDER=my_custom_provider
CUSTOM_API_KEY=your_custom_api_key
CUSTOM_API_BASE=https://your-custom-endpoint.com/v1

# Admin Configuration
ADMIN_API_KEY=your_secure_admin_key_here

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# CORS Configuration (comma-separated list)
CORS_ORIGINS=*